# Проект от идеи до прототипа

Разработка проекта связана с решением определённых поставленных задач и является ориентированной на пользователей. Садясь за любую разработку стоит в первую очередь потребности пользователя. Каждый проект должен был в первую очередь описан главными целями и метрикам их достижения.

## Введение и общая информация

Любой проект имеет прикладную область - это домен в рамках которого выполняется моделирование. Допустим, мы захотим писать новый электронный маркет, то разработка будет крутиться вокруг предметов, каталогов, доставок, оплат. Важно иметь glossary, чтобы все участники проекта имели единственную и правильную трактовку.

## User story

> TODO: I1

Проводя анализ запросов пользователей и текущих процессов можно сформировать User stories. Но важно понимать какое бизнес вэлью несёт на или иная юзер стори. Если US сложная в разработке или поддержке и нужна малому количеству пользователей в ограниченных сценариях, то её ценностью очень сомнительна. Подобные рассуждения требуют комплексного анализа и выходят за рамки этого повествования.

Зачем же юзер стори? Это шаблон, который показывает необходимый и достаточных объем описания требования, но при этом не вдаваясь в технически детали. Если мы спроецируем наш проект на юзер стори, то в итоге получим полное представление о том, что нам предстоит сделать. Типичный шаблон юзер стори:

- As a [type of user],
- I want [an action]
- so that [a benefit/value]

## Процесс as-is|to-be

Ещё одна проекция проекта - это процессы, которые описывают как работает система. Разрабатывая новый продукт или дорабатывая старый нужно понимать какое место в основном процессе он займёт, с чем он должен интегрироваться, от чего зависеть. Можно сформировать формальное описание процесса как он есть сейчас и каким он должен.

## Постановка задач

Юзер стори обычно являются объемными и подлежат декомпозиции на более мелкие задачи. Таким образом юзер стори разбивается на несколько шагов. Важные атрибуты задач, которые должны быть (большинство систем управления задачами их предоставляют):

- Идентификатор задачи
- Название и описание
- Состояние - открыта, в процессе, выполнена. Дополнительно могут быть введены шаги для этапа тестирования
- Назначенный сотрудник. Задача не может висеть в воздухе, за неё кто-то должен отвечать. Даже если её не выполняют сейчас, она должна быть отдана сотруднику, который выполнит её или назначит на другого
- Приоритет. Задача может быть как важной, так и записанной на случай свободного времени. Чтобы лучше ориентироваться в порядке выполнения, задачи обычно имеют приоритет

## Выполнение задачи

Сформулированная задача не обязательно попадает сразу на выполнение. С большой вероятностью задачи попадают изначально в очередь. Одна из задач менеджеров - это контролировать эту очередь, выбирать скоуп задач для команды на итерацию в соответствии с приоритетами. Важно также отметить, что тенденция современных подходов к разработке заключается в переизбытке задач. Не стоит удивляться тому, что на команде всегда больше задач, чем она может успеть выполнить. Это проблемы компаний, который скейлят продукт быстрее чем команды, с этим нужно учиться жить. Именно поэтому важны приоритеты - некоторые задачи вообще не несут ценности и могут лежать годами. Но выбрасывать их также не нужно ввиду того, что задача может заиграть новыми красками в контексте нового функционала или изменений приоритетов.

Но не всё так плохо и задача может попасть в список приоритетных. В этот момент у многих рисуется картина, как архитектор стоит над кодом и вырисовывает новый код. Но на деле бывает сильно иначе. Если говорить про CRUD и подобного уровня задачи, то они легко сводятся к тому, что человек с относительно даже не большим опытом может взять задачу и по аналогии её сделать не прибегая к использованию ресурсов более опытных товарищей. Разве что ревью. Задача может быть не крудом, но процесс может быть построен так, что задачи - это ряд интеграция между мелкими фичами, которые не требуют экспертизы и глобального понимания архитектуры, а лишь потратить время на речёрч низкоуровневых особенностей кода. Где-то в этот момент задача из категории ресёрча плавно переходит в написание кода. По результатам написания кода в зависимости от построенных процессов задача может развиваться разными способами. Есть воркфлоу, когда за разработкой идёт процесс деплоя, чтобы изменения развернуть на тестовой среде и зашарить апдейты команде QA. Если накатывание апдейтов - это автоматизированная операция, то можно считать, что изменения улетели на тестирование и мячик уже на стороне QA.

## Тестирование

Как бы хорошо не был написан код, рано или поздно в него попадут баги. Поэтому, как часть процесса разработки выделяют тестирование. Тестирование может происходить на разных этапах.

Самый ранний этап, когда может происходить тестирование - до написания самого кода. Существует подход, который называется TDD. Если кратко и упрощённо, то идея заключается в том, чтобы формализовать требования и функционал в формате тестов. Т.е. мы берём требование и пишем на него тест - последовательность действий и ожидаемые проверки. Разумеется, пока функционал не написан, тесты будут падать. И имплементация заключается как раз в том, чтобы падающие тесты оживить.

Но TDD не используют повсеместно. Более распространённый подход к написанию тестов - это юнит тесты. Это тип тестов в коде, которые пишут для проверки работы отдельно взятого функционала, метода. Цель таких тестов - убедиться, что каждый отдельно взятый элемент работает. Он позволит убедиться, например, что написанная логика сортировки элементов по нужным критериям работает вне зависимости от того, что это за элементы, откуда они прочитались и подобное. Количество юнит тестов, которые нужно для достаточно покрытия довольно большое. Настолько большое, что это слишком дорого для компаний. В условиях нехватки кадров и времени, выделять много времени на реализацию кода, которые не продаётся - это неоправданная цена может быть.

Как и всегда с тестами нужно сделать выбор. Они имеют цену и ценность. Ценность тестов может заключаться в том, что разработчик так ускорил себе проверку написанного кода, чтобы убедиться, что всё ок и влить. Но куда чаще тесты пишутся с целью защитить поведение от изменения, чтобы быть уверенными, что рефакторя код, он не сломается и не станет работать иначе. Но у этого есть и цена - поддержка тестов. Тесты не несут бизнес вэлью сами по себе. Для менеджеров они вообще могут выглядеть как трата времени разработчиков вникуда. Помимо написания, тесты ещё требуют поддержки. Если меняется логика/АПИ/требования, то вместо того, чтобы поправить одно место, нужно также пробежаться по всем местам. Это не всегда быстро, особенно, когда количество тестов проходит черту в 15к.

Помимо юнит тестов есть более обширные тесты - интеграционные. Их задача состоит в проверке работоспособности на стыке различных компонентов. Такие тесты завязаны сразу на много микромоментов. Этим они снижают свою цену - их нужно меньше, чтобы покрыть код. В таких тестах реже приходится решать задачу зависимостей от инфраструктуры (которая является болью юнит тестов). Пока речь идёт всё ещё про тесты на уровне кода. Их основное преимущество в том, что они лежат рядом с кодом и в том, что это запускаемый код. У разработчиков есть возможность такие тесты запустить и за относительно короткое время узнать состояние продукта.

Следующий этап - это выход тестирования за пределы кода. В сложных системах почти всегда функционал выходит за рамки CRUD'а. Всё чаще необходимо развернуть какое-то окружение, взаимодействовать с какими-то системами. Например, в обычных тестах довольно сложно реализовать проверку работы балансировки распределённой файловой системы и логики её балансировки. Для этого не обходимо несколько нод поднять, файлы создать и разбросать по нужным местам. Да, это можно автоматизировать, но это выходит за рамки простого теста. Такие вещи очень часто делают с помощью автотестов используя скрипты, PowerShell, Postman сценарии и т.д.. В таком случае, запуская на виртуальной машине тест, можно получить в результате не только информацию о падении, а и логи, которые спосойно генерятся не зависимо от других тестов, а также состояние базы и прочее.

Последний и самым менее приятным уровнем тестирования можно назвать ручное тестирование. Оно заключается в том, чтобы взять приложение, запустить и начать тыкать на соответствие требованиям. Зачем это нужно, если всё и так автоматически тестируется? Проблема заключатся как раз в том, чт автоматически мало что тестируется. Не всегда есть понимание как нужно тестировать, на что смотреть. Сложно быть уверенным в том, что зелёный тест подтвердит работоспособность. Тест может банально не иметь проверку на то место, которое не работает. Именно по этому ещё существует и достаточно распространены тестировщики. Один из этапов, на ручное тестирование имеет больше ценности - это регресс. Регресс - это процесс проверки всего продукта в целью довести его до минимального количества багов. Для него не достаточно тестов, скорее наоборот ожидается более глубокий анализ каждой части с возможностью точечно протестировать более детально отдельно взятый элемент или часть.

Не смотря на то, что баги - это вотчина тестировщиков, даже для внутренней разработки, когда у вас нет выделенных тестировщиков, не лишним будет узнать про best practice формализации. Из очевидных вещей - баги как и таски должны иметь уникльные идентификаторы, трекаться вместе с задачами и быть максимально близко к коду (а не заметками в трелло, например). Описание баги всегда должно оперировать двумя состояниями - ожидаемое поведение и текущее. Если в баге описано только ожидаемое, то не ясно что не так. Если в баге описано только текущее, то может быть не очевидно, что ожидается. Разумеется, если бага звучит как "Летит Null reference при попытке запустить код", то тут очевидно ожидание. Но в более сложных кейсах поведение имеет смысл согласовывать с ответственными. Поэтому важно иметь задокументированный ориентир. Ну и важно понимать, что чем больше информации о контексте бага, тем больше шанс его решить (и сделать это быстрее). Поэтому баги должны быть ассоциированы с версией или билдом продукта, а также дополняться информацией о том, какая была инфраструктура, что с ней делали и как влияли на приложение для получения бага. Лучшим исходом является чёткое описание способа воспроизвести проблему.

## Мейлстоуны, прототипы и выкатка версий для пользователя

В идеальном мире можно представить воркфлоу, когда проект проектируется, начинается реализовываться, реализовывается, отдаётся кастомерам, они платят деньги и все довольны. В реальном же мире всё сильно сложнее. Завязка на пользователях иногда играет разрушительную роль с проектами. Даже если проект разрабатывался с оглядкой на потребность пользователей,  он может не учесть динамически изменяющийся мир. Хорошим примером может быть ковид, который создал поле для пополнения аудитории. Этим воспользовался Зум. Но помимо зума много других компаний попытались на этой волне внедрить свои решения для конференций. И чем это закончилось? Для многих это закончилось тем, что они вышли на рынок, когда уже не нужны были. Не смотря на то, что он был отватительно неюзабельным, он смог получить какое-то количество пользователей. И всё, что ему нужно было дальше - это получать фидбек и понимать ожидания. Какими бы не были попытки анализировать рынок и заранее готовить требования, это не сравниться с тем, чтобы дать пользователям попробовать и получить фидбек. Даже в деталях могу крыться фатальные недостатки, которые могут заметить пользователи, зарепортить, получить фикс и быть довольными. Это всё ведёт к тому, что продукт нужно показывать до того, как окончательно зарелизить. Можно ли без этого? Да, но какой ценой? Пользователи зарепортят проблемы и будут ждать ещё одного цикла разработки, тестирования и обновления. И хорошо, если вы пишете REST API. А теперь представьте ситуацию с продуктом, который выпускается раз в полгода.

Во время обсуждения релизом, может сложиться ситуация, что это проблемы людей более высоких уровней чем разработчики, но это не так. Описанная проблема точно также существует и на уровне кода. Можно заменить выпуск версии на реализацию своего компонента/интерфейса. И внезапно может оказаться, что команда разрабатывает модуль, проектирует её интерфейс, а по итогу оказывается, что он совершенно не стыкуется с теми потребностями, которые предоставила соседняя команде к нему. "У нас идеально спроектированный бек. Жаль только половина фичей фронт не использует". Также, прототипы - это отличный способ оценить сложность разработки. Если декомпозиция не помогает и есть понимание, что модуль может быть реализован за 6-60 недель, то имеет смысл брать время на разработку прототипа. Он поможет разобраться с кодовой базой, выявить проблемы, а самое главное - показать предварительное решение, которое упростит как оценку, так и планирование по использованию разработанного модуля.

Если говорить про примеры мэйлстоунов, то в первую очередь это прототип. Его задача - показать функционал. От него не ожидают, что это будет готовый продукт, но по нему можно дать фидбек и скорректировать работу. Помимо прототипа часто используется формулировка MVP - minimal value product. Это представление системы, которое содержит весь необходимый функционал для решения поставленных задач и достижения цели. Но не более. Для его выпуска могут отказаться от удобства, интеграций, UX, некоторых корнер кейсов или негативных сценариев. Но это уже приблизительно тот продукт, который будет отдан пользователям и они должны быть удовлетворены. Далее могут уже идти альфы, беты, превью и прочее, требования к которым всё также устанавливает каждая отдельно взятая компания для себя.

## Рост стоимости задачи

И всё же, что нам мешает просто изменить продукт и выпустить его ещё раз? Мешает стоимость такого. Самое первое что приходит в голову - это выпуск вовремя. Представим, что есть две конкурирующие платформы для продажи игр и игра, которую ждут пользователи. Если они в один день выпустят игру, то будут конкурировать на около равных и всё зависит от тх market share. Но если первая платформа уже выпустила, а вторая не успела, то начинается волна убытков. И каждый следующий день (если не час!) будет продолжат уменьшать общий доход платформы. Так что в некоторых ситуациях нельзя просто взять и выпустить продукт на пару дней позже.

Рассмотрим появление бага и попытки его отловить. Баги, которые находятся компилятором являются самыми дешёвыми т.к. они замедлят разработку лишь на время ещё одной сборки продукта. Но это довольно узкий скоуп проблем, а в некоторых языках вообще стремиться к 0. Следующий этап - это юнит и интеграционные тесты. Те самые тесты, которые пишут разработчики, чтобы выявить проблему заранее, до запуска и развёртывания приложения. Если бага прошла через все эти слои и не покрылась тестами, то она могла дойти до отдела QA. Если проблема выявить на этапе QA, то это уже заденет несколько человек, будет требовать переконфирма, времени на ресёрч и поиск проблемы. Следующий этап - это нахождение проблемы на этапе регресса. И в этот момент появляется дополнительная цена изменений - уже всё протестировано. Нужно либо делать это ещё раз и тратить дни/недели либо ставить свечку за то, чтобы фикс не привнёс новых проблем. И разумеется критичными моментами являются нахождения проблем пользователями. Это уже привносит проблемы компании перед пользователями (особенно, если они могут что-то сломать), это в разы сложнее анализировать т.к. данных может быть минимальное количество (если вы разрабатываете коробочное решение, а пользователь не может поделиться подробностями инфраструктуры). И в этот момент превью или бета билды дают возможность на небольшом количестве пользователей собрать баги (к тому же, они осознают, что они будут ловить ошибки). Последний эта проблем - это совместимость со старыми клиентами. Если вы разрабатываете Todo лист, то можно относительно без проблем выпустить новую версию с фиксами. Но что если у вас клиент-серверное приложение и проблемы на стороне сервера? Просто обновить сервер, когда уже он оброс клиентами, просто так не получится. Ваши клиенты могут ожидать, что вы не сломаете им возможность работать при первом же обновлении. И тогда цена ошибки превращается в том, что нужно ещё несколько версий поддерживать проблемные места в API.

## Sources

- [https://medium.com/@alexandertvar/как-писать-user-story-2410093b23c2](https://medium.com/@alexandertvar/%D0%BA%D0%B0%D0%BA-%D0%BF%D0%B8%D1%81%D0%B0%D1%82%D1%8C-user-story-2410093b23c2)
- [https://xp123.com/articles/invest-in-good-stories-and-smart-tasks](https://xp123.com/articles/invest-in-good-stories-and-smart-tasks/)
- [https://www.digite.com/agile/user-stories/](https://www.digite.com/agile/user-stories/)